{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyM4MC8eFa3wyh9qqpWolxk4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"y9RVZ2TP15wH"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y8cDtxLIBHgQ","outputId":"c952d46b-949d-4512-f76a-afba87d17e33","executionInfo":{"status":"ok","timestamp":1709640702286,"user_tz":-120,"elapsed":603,"user":{"displayName":"Mohammad Reve","userId":"07554969775192999584"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Tue Mar  5 12:11:42 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n","| N/A   44C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","|  No running processes found                                                           |\n","+---------------------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CjpPg4mGKc1v","outputId":"5adb7ae4-7502-4f45-d1bc-6a05fc67ffa3","executionInfo":{"status":"ok","timestamp":1709640709665,"user_tz":-120,"elapsed":619,"user":{"displayName":"Mohammad Reve","userId":"07554969775192999584"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}],"source":["import os\n","HOME = os.getcwd()\n","print(HOME)"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tdSMcABDNKW-","outputId":"3e0ce26d-9178-4a67-89ce-192b2719c991","executionInfo":{"status":"ok","timestamp":1709640915771,"user_tz":-120,"elapsed":13267,"user":{"displayName":"Mohammad Reve","userId":"07554969775192999584"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["Ultralytics YOLOv8.0.196 ðŸš€ Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","Setup complete âœ… (2 CPUs, 12.7 GB RAM, 26.3/78.2 GB disk)\n"]}],"source":["# Pip install method (recommended)\n","\n","!pip install ultralytics==8.0.196\n","\n","from IPython import display\n","display.clear_output()\n","\n","import ultralytics\n","ultralytics.checks()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VOEYrlBoP9-E"},"outputs":[],"source":["from ultralytics import YOLO\n","\n","from IPython.display import display, Image"]},{"cell_type":"code","source":["!pip install roboflow\n","\n","from roboflow import Roboflow\n","rf = Roboflow(api_key=\"zvSQDWlFzNBOBhClo61R\")\n","project = rf.workspace(\"ieee-project\").project(\"sign_lang-4s3vr\")\n","version = project.version(2)\n","dataset = version.download(\"yolov8\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3I2C7Bwq4JwF","executionInfo":{"status":"ok","timestamp":1709564076836,"user_tz":-120,"elapsed":9343,"user":{"displayName":"Mohammad Reve","userId":"07554969775192999584"}},"outputId":"f1f6d713-ec9f-4bb5-89ab-009b5c3bae5c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: roboflow in /usr/local/lib/python3.10/dist-packages (1.1.21)\n","Requirement already satisfied: certifi==2023.7.22 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2023.7.22)\n","Requirement already satisfied: chardet==4.0.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.0.0)\n","Requirement already satisfied: cycler==0.10.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.10.0)\n","Requirement already satisfied: idna==2.10 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.10)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.5)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7.1)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.25.2)\n","Requirement already satisfied: opencv-python-headless==4.8.0.74 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.8.0.74)\n","Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (9.4.0)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n","Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.0.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.31.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.16.0)\n","Requirement already satisfied: supervision in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.18.0)\n","Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.0.7)\n","Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.66.2)\n","Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0.1)\n","Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.0.0)\n","Requirement already satisfied: python-magic in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.4.27)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.2.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.49.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (23.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (3.1.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (3.3.2)\n","Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from supervision->roboflow) (0.7.1)\n","Requirement already satisfied: scipy<2.0.0,>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from supervision->roboflow) (1.11.4)\n","loading Roboflow workspace...\n","loading Roboflow project...\n"]}]},{"cell_type":"code","source":["%cd {HOME}\n","\n","!yolo task=detect mode=train model=yolov8s.pt data={dataset.location}/data.yaml epochs=25 imgsz=800 plots=True"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vD1ZG7Re4hHz","executionInfo":{"status":"ok","timestamp":1709564231551,"user_tz":-120,"elapsed":147205,"user":{"displayName":"Mohammad Reve","userId":"07554969775192999584"}},"outputId":"cf900347-0c82-4f38-d66e-b80d435e1e4a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8s.pt to 'yolov8s.pt'...\n","100% 21.5M/21.5M [00:00<00:00, 74.0MB/s]\n","New https://pypi.org/project/ultralytics/8.1.23 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n","Ultralytics YOLOv8.0.196 ðŸš€ Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=/content/Sign_Lang-2/data.yaml, epochs=25, patience=50, batch=16, imgsz=800, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n","Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n","100% 755k/755k [00:00<00:00, 140MB/s]\n","2024-03-04 14:54:57.925010: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-03-04 14:54:57.925078: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-03-04 14:54:57.926787: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","Overriding model.yaml nc=80 with nc=5\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2117983  ultralytics.nn.modules.head.Detect           [5, [128, 256, 512]]          \n","Model summary: 225 layers, 11137535 parameters, 11137519 gradients, 28.7 GFLOPs\n","\n","Transferred 349/355 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n","Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to 'yolov8n.pt'...\n","100% 6.23M/6.23M [00:00<00:00, 265MB/s]\n","WARNING âš ï¸ NMS time limit 0.550s exceeded\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/Sign_Lang-2/train/labels... 108 images, 0 backgrounds, 0 corrupt: 100% 108/108 [00:00<00:00, 1561.52it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/Sign_Lang-2/train/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/Sign_Lang-2/valid/labels... 10 images, 0 backgrounds, 0 corrupt: 100% 10/10 [00:00<00:00, 1297.50it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/Sign_Lang-2/valid/labels.cache\n","Plotting labels to runs/detect/train/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001111, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n","Image sizes 800 train, 800 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1mruns/detect/train\u001b[0m\n","Starting training for 25 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       1/25      6.15G      1.629      7.361      1.825         30        800: 100% 7/7 [00:06<00:00,  1.01it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:01<00:00,  1.72s/it]\n","                   all         10         10      0.256       0.25    0.00821    0.00335\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       2/25      6.36G      1.416      5.263      1.686         21        800: 100% 7/7 [00:03<00:00,  2.29it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.55it/s]\n","                   all         10         10      0.651      0.769      0.831       0.62\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       3/25      6.43G     0.8345      2.476      1.205         25        800: 100% 7/7 [00:02<00:00,  2.36it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.37it/s]\n","                   all         10         10       0.83       0.75      0.829      0.732\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       4/25      6.43G     0.7413      1.823      1.112         19        800: 100% 7/7 [00:02<00:00,  2.64it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  5.57it/s]\n","                   all         10         10      0.729          1      0.995      0.852\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       5/25      6.28G     0.6457      1.437      1.044         23        800: 100% 7/7 [00:02<00:00,  2.58it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  3.92it/s]\n","                   all         10         10       0.49          1      0.648      0.607\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       6/25      6.42G     0.6601      1.206      1.049         26        800: 100% 7/7 [00:02<00:00,  2.47it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.85it/s]\n","                   all         10         10       0.75        0.5       0.56      0.523\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       7/25      6.27G     0.6454      1.155      1.058         26        800: 100% 7/7 [00:02<00:00,  2.52it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  4.57it/s]\n","                   all         10         10      0.611          1      0.782       0.69\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       8/25      6.43G     0.7315      1.128      1.112         25        800: 100% 7/7 [00:02<00:00,  2.61it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  7.95it/s]\n","                   all         10         10      0.891      0.958      0.995      0.843\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       9/25      6.44G     0.6906     0.9537      1.093         21        800: 100% 7/7 [00:02<00:00,  2.56it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  4.36it/s]\n","                   all         10         10      0.973          1      0.995      0.826\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      10/25      6.42G     0.6519     0.8443      1.023         23        800: 100% 7/7 [00:02<00:00,  2.40it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  5.22it/s]\n","                   all         10         10       0.94          1      0.995      0.803\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      11/25      6.27G     0.6069      0.835     0.9913         23        800: 100% 7/7 [00:02<00:00,  2.67it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  5.43it/s]\n","                   all         10         10      0.951          1      0.995      0.833\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      12/25      6.46G     0.6445     0.7656      1.029         19        800: 100% 7/7 [00:02<00:00,  2.61it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  5.14it/s]\n","                   all         10         10      0.923      0.983      0.995      0.827\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      13/25      6.43G     0.6157     0.7373      1.001         23        800: 100% 7/7 [00:02<00:00,  2.48it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  3.03it/s]\n","                   all         10         10      0.818      0.926      0.995      0.837\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      14/25      6.45G     0.5754     0.7329     0.9937         19        800: 100% 7/7 [00:02<00:00,  2.68it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  5.95it/s]\n","                   all         10         10      0.944      0.925      0.995      0.832\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      15/25      6.44G     0.6506      0.763      1.026         24        800: 100% 7/7 [00:02<00:00,  2.36it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  3.87it/s]\n","                   all         10         10      0.954          1      0.995      0.876\n","Closing dataloader mosaic\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      16/25      6.27G     0.5117     0.6289     0.9787         12        800: 100% 7/7 [00:05<00:00,  1.22it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  4.29it/s]\n","                   all         10         10      0.838      0.916      0.995        0.9\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      17/25      6.43G     0.5194     0.6551     0.9711         12        800: 100% 7/7 [00:02<00:00,  2.61it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  6.35it/s]\n","                   all         10         10      0.842      0.982      0.995      0.776\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      18/25      6.44G     0.4659     0.5564     0.9409         12        800: 100% 7/7 [00:02<00:00,  2.63it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  4.01it/s]\n","                   all         10         10      0.931       0.96      0.995      0.847\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      19/25      6.45G     0.4547     0.5533     0.9524         12        800: 100% 7/7 [00:02<00:00,  2.38it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  4.63it/s]\n","                   all         10         10       0.71      0.879      0.995      0.877\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      20/25      6.28G     0.4954     0.5504     0.9776         12        800: 100% 7/7 [00:02<00:00,  2.61it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  8.39it/s]\n","                   all         10         10      0.734       0.85      0.995      0.846\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      21/25      6.43G     0.4226     0.4855      0.901         12        800: 100% 7/7 [00:02<00:00,  2.62it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  5.13it/s]\n","                   all         10         10      0.727      0.843      0.953      0.784\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      22/25      6.45G     0.4156      0.478     0.8955         12        800: 100% 7/7 [00:02<00:00,  2.35it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  3.75it/s]\n","                   all         10         10       0.86      0.828      0.912       0.76\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      23/25      6.45G     0.3916      0.453      0.918         12        800: 100% 7/7 [00:02<00:00,  2.61it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  7.03it/s]\n","                   all         10         10      0.887      0.851      0.995      0.861\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      24/25      6.29G     0.4021     0.4212     0.8865         12        800: 100% 7/7 [00:02<00:00,  2.62it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  6.74it/s]\n","                   all         10         10      0.893      0.859      0.995      0.879\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      25/25      6.43G     0.3691     0.4099     0.8645         12        800: 100% 7/7 [00:02<00:00,  2.55it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  3.27it/s]\n","                   all         10         10      0.908      0.859      0.995      0.865\n","\n","25 epochs completed in 0.031 hours.\n","Optimizer stripped from runs/detect/train/weights/last.pt, 22.5MB\n","Optimizer stripped from runs/detect/train/weights/best.pt, 22.5MB\n","\n","Validating runs/detect/train/weights/best.pt...\n","Ultralytics YOLOv8.0.196 ðŸš€ Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","Model summary (fused): 168 layers, 11127519 parameters, 0 gradients, 28.4 GFLOPs\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  8.17it/s]\n","                   all         10         10      0.839      0.916      0.995        0.9\n","                 Hello         10          2      0.661          1      0.995      0.995\n","            I-Love-You         10          5          1      0.686      0.995      0.864\n","                    No         10          1      0.693          1      0.995      0.796\n","             Thank-You         10          2          1      0.978      0.995      0.945\n","Speed: 0.2ms preprocess, 5.1ms inference, 0.0ms loss, 1.0ms postprocess per image\n","Results saved to \u001b[1mruns/detect/train\u001b[0m\n","ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n"]}]},{"cell_type":"code","source":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":106},"id":"oMOENWNP_z7A","executionInfo":{"status":"error","timestamp":1709547949271,"user_tz":-120,"elapsed":504,"user":{"displayName":"Mohammad Reve","userId":"07554969775192999584"}},"outputId":"b637b8ef-1a53-4da2-d22b-02eeed903764"},"execution_count":null,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"invalid syntax (<ipython-input-2-69085160737d>, line 1)","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-69085160737d>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    sudo apt install libgtk2.0-dev\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]},{"cell_type":"code","source":["\n","import cv2\n","import torch\n","\n","# Error handling: Ensure the model file exists before loading\n","model_path = 'yolov8s.pt'\n","try:\n","    model = torch.load(model_path)\n","    print(f\"YOLOv8 model loaded successfully from: {model_path}\")\n","except FileNotFoundError:\n","    print(f\"Error: Model file not found at: {model_path}\")\n","    exit()\n","\n","# Open the video stream (replace 0 for webcam, path for video file)\n","cap = cv2.VideoCapture(0)\n","\n","# Error handling: Check if the video stream can be opened\n","if not cap.isOpened():\n","    print(\"Error: Could not open video stream.\")\n","    exit()\n","\n","# Loop continuously until the user presses 'Esc'\n","while True:\n","    # Capture frame-by-frame\n","    ret, frame = cap.read()\n","\n","    # Check if frame is read successfully\n","    if not ret:\n","        print(\"Error: Failed to read frame.\")\n","        break\n","\n","    # Perform YOLOv8 inference on the frame (specific implementation depends on YOLOv8 API)\n","    with torch.no_grad():\n","        # ... (Replace with your YOLOv8 inference code to get detections)\n","        # For example, if YOLOv8 returns a list of dictionaries containing bounding box coordinates, class labels, and confidence scores:\n","        detections = [\n","            {'xmin': 100, 'ymin': 50, 'xmax': 200, 'ymax': 150, 'class': 'person', 'confidence': 0.8},\n","            {'xmin': 300, 'ymin': 200, 'xmax': 450, 'ymax': 350, 'class': 'car', 'confidence': 0.7}\n","        ]\n","\n","    # Process and visualize detections (adapt based on your needs)\n","    for detection in detections:\n","        # Extract bounding box coordinates\n","        xmin, ymin, xmax, ymax = detection['xmin'], detection['ymin'], detection['xmax'], detection['ymax']\n","\n","        # Draw bounding box on the frame\n","        cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n","\n","        # Display class label and confidence score (optional)\n","        text = f\"{detection['class']}: {detection['confidence']:.2f}\"\n","        cv2.putText(frame, text, (xmin, ymin - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n","\n","    # Display the resulting frame\n","    cv2.imshow('YOLOv8 Detection', frame)\n","\n","    # Check for user input to exit\n","    if cv2.waitKey(1) & 0xFF == 27:  # Press 'Esc' to quit\n","        break\n","\n","# Release resources\n","cap.release()\n","cv2.destroyAllWindows()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":245},"id":"sWyyeBrK-MBm","executionInfo":{"status":"error","timestamp":1709548004687,"user_tz":-120,"elapsed":5155,"user":{"displayName":"Mohammad Reve","userId":"07554969775192999584"}},"outputId":"964709ef-2e67-4127-b317-b7fad7d7485b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["YOLOv8 model loaded successfully from: yolov8s.pt\n","Error: Could not open video stream.\n","Error: Failed to read frame.\n"]},{"output_type":"error","ename":"error","evalue":"OpenCV(4.8.0) /io/opencv/modules/highgui/src/window.cpp:1266: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvDestroyAllWindows'\n","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-af11d657ec65>\u001b[0m in \u001b[0;36m<cell line: 61>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;31m# Release resources\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdestroyAllWindows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31merror\u001b[0m: OpenCV(4.8.0) /io/opencv/modules/highgui/src/window.cpp:1266: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvDestroyAllWindows'\n"]}]},{"cell_type":"code","source":["\n","\n","import cv2\n","import numpy as np\n","import torch\n","\n","# Replace 'path/to/yolov8s.pt' with the actual path to your model file\n","model = torch.load('yolov8s.pt')\n","\n","# Now you can use the loaded model for inference or other purposes\n","\n","# Open webcam\n","cap = cv2.VideoCapture(0)\n","\n","while cap.isOpened():\n","    ret, frame = cap.read()\n","    if not ret:\n","        break\n","\n","    # Perform object detection using YOLOv8\n","    results = model(frame)\n","\n","    # Process detection results\n","    for box, conf, cls in results.xyxy[0]:\n","        label = f\"{model.names[int(cls)]}: {conf:.2f}\"\n","        cv2.rectangle(frame, (int(box[0]), int(box[1])), (int(box[2]), int(box[3])), (0, 255, 0), 2)\n","        cv2.putText(frame, label, (int(box[0]), int(box[1] - 10)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n","\n","    # Display the frame with detections\n","    cv2.imshow(\"YOLOv8 Object Detection\", frame)\n","\n","    if cv2.waitKey(1) & 0xFF == 27:   # Press 'Esc' to exit\n","        break\n","\n","cap.release()\n","cv2.destroyAllWindows()\n"],"metadata":{"id":"2t_zbxIe7Z5Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ciV94EbA5_4g"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Reading numbers frame 0.01s Test  "],"metadata":{"id":"6YqUQ9SLftGP"}},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","from tensorflow.keras.models import load_model\n","\n","# Load your trained model\n","model_path = \"sign.h5\"  # Replace with the actual path to your trained model\n","model = load_model(model_path)\n","\n","# Compile the model with your desired settings\n","model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n","\n","# Create a mapping for class labels\n","class_mapping = {\n","    0: \"0\",\n","    1: \"1\",\n","    2: \"2\",\n","    3: \"3\",\n","    4: \"4\",\n","    5: \"5\",\n","    6: \"6\",\n","    7: \"7\",\n","    8: \"8\",\n","    9: \"9\",\n","}\n","\n","# Open webcam\n","cap = cv2.VideoCapture(0)\n","while cap.isOpened():\n","    ret, frame = cap.read()\n","    if not ret:\n","        break\n","\n","    # Resize the frame to match the input size expected by your model\n","    frame_resized = cv2.resize(frame, (100, 100))\n","\n","    # Expand dimensions to create a batch-sized image\n","    img_array = np.expand_dims(frame_resized, axis=0)\n","\n","    # Modify the preprocessing based on your model's requirements\n","    img_array = img_array.astype(np.float32) / 255.0\n","\n","    # Make predictions using your model\n","    predictions = model.predict(img_array)\n","\n","    # Assuming a single-class prediction\n","    predicted_class = np.argmax(predictions)\n","    predicted_label = class_mapping[predicted_class]\n","\n","    # Display the predicted label on the frame\n","    cv2.putText(\n","        frame,\n","        predicted_label,\n","        (50, 50),\n","        cv2.FONT_HERSHEY_SIMPLEX,\n","        1,\n","        (0, 255, 0),\n","        2,\n","    )\n","\n","    # Display the frame\n","    cv2.imshow(\"Model Prediction\", frame)\n","\n","    if cv2.waitKey(1) & 0xFF == 27:  # Press 'Esc' to exit\n","        break\n","\n","cap.release()\n","cv2.destroyAllWindows()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"id":"16zK2L3U503M","executionInfo":{"status":"error","timestamp":1709546710297,"user_tz":-120,"elapsed":3868,"user":{"displayName":"Mohammad Reve","userId":"07554969775192999584"}},"outputId":"3320364a-6407-4d22-bda8-dc256ebe4d8c"},"execution_count":null,"outputs":[{"output_type":"error","ename":"OSError","evalue":"No file or directory found at sign.h5","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-4541e70ea011>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Load your trained model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"sign.h5\"\u001b[0m  \u001b[0;31m# Replace with the actual path to your trained model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Compile the model with your desired settings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;31m# Legacy case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m     return legacy_sm_saving_lib.load_model(\n\u001b[0m\u001b[1;32m    263\u001b[0m         \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/legacy/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    232\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                             raise IOError(\n\u001b[0m\u001b[1;32m    235\u001b[0m                                 \u001b[0;34mf\"No file or directory found at {filepath_str}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                             )\n","\u001b[0;31mOSError\u001b[0m: No file or directory found at sign.h5"]}]}]}